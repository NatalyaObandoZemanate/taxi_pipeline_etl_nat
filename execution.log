
2025-04-26 12:41:26,367 - INFO - Iniciando ejecuciï¿½n del pipeline...
2025-04-26 12:41:26,367 - INFO - Iniciando sesiï¿½n de Spark...
2025-04-26 12:41:31,338 - INFO - \U0001f4e5 Descargando archivos Parquet desde la web pï¿½blica...
2025-04-26 12:41:31,338 - INFO - yellow_tripdata_2022-01.parquet ya existe. Se omite descarga.
2025-04-26 12:41:31,338 - INFO - yellow_tripdata_2022-02.parquet ya existe. Se omite descarga.
2025-04-26 12:41:31,339 - INFO - yellow_tripdata_2022-03.parquet ya existe. Se omite descarga.
2025-04-26 12:41:31,339 - INFO - yellow_tripdata_2022-04.parquet ya existe. Se omite descarga.
2025-04-26 12:41:31,339 - INFO - yellow_tripdata_2022-05.parquet ya existe. Se omite descarga.
2025-04-26 12:41:31,339 - INFO - yellow_tripdata_2022-06.parquet ya existe. Se omite descarga.
2025-04-26 12:41:31,339 - INFO - yellow_tripdata_2022-07.parquet ya existe. Se omite descarga.
2025-04-26 12:41:31,340 - INFO - yellow_tripdata_2022-08.parquet ya existe. Se omite descarga.
2025-04-26 12:41:31,340 - INFO - yellow_tripdata_2022-09.parquet ya existe. Se omite descarga.
2025-04-26 12:41:31,340 - INFO - yellow_tripdata_2022-10.parquet ya existe. Se omite descarga.
2025-04-26 12:41:31,340 - INFO - yellow_tripdata_2022-11.parquet ya existe. Se omite descarga.
2025-04-26 12:41:31,340 - INFO - yellow_tripdata_2022-12.parquet ya existe. Se omite descarga.
2025-04-26 12:41:31,340 - INFO - \U0001f4c2 Cargando archivos Parquet en Spark...
2025-04-26 12:41:37,285 - INFO - \u2705 Datos cargados con 39656098 registros.
2025-04-26 12:41:37,710 - INFO - Registros cargados en Raw Layer: 39656098
2025-04-26 12:41:37,710 - INFO - \U0001f4be Guardando datos RAW...
2025-04-26 12:41:48,587 - INFO - Iniciando ejecuciï¿½n del pipeline...
2025-04-26 12:41:48,587 - INFO - Iniciando sesiï¿½n de Spark...
2025-04-26 12:41:56,029 - ERROR - \u274c ERROR en la ejecuciï¿½n: An error occurred while calling o36.parquet.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 7.0 failed 1 times, most recent failure: Lost task 6.0 in stage 7.0 (TID 33) (kubernetes.docker.internal executor driver): java.lang.OutOfMemoryError: Java heap space


Driver stacktrace:

	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)

	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)

	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)

	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)

	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)

	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)

	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)

	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)

	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)

	at scala.Option.foreach(Option.scala:407)

	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)

	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)

	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)

	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)

	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)

	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)

	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)

	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$4(FileFormatWriter.scala:307)

	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:271)

	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)

	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)

	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)

	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)

	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)

	at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)

	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)

	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)

	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)

	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)

	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)

	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)

	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)

	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)

	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)

	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)

	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)

	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)

	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)

	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)

	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)

	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)

	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)

	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)

	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)

	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)

	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)

	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)

	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)

	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)

	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243)

	at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:802)

	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)

	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)

	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)

	at java.base/java.lang.reflect.Method.invoke(Method.java:580)

	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)

	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)

	at py4j.Gateway.invoke(Gateway.java:282)

	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)

	at py4j.commands.CallCommand.execute(CallCommand.java:79)

	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)

	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)

	at java.base/java.lang.Thread.run(Thread.java:1583)

Caused by: java.lang.OutOfMemoryError: Java heap space


2025-04-26 12:41:56,081 - INFO - Closing down clientserver connection
2025-04-26 12:41:59,272 - INFO - \U0001f4e5 Descargando archivos Parquet desde la web pï¿½blica...
2025-04-26 12:41:59,273 - INFO - yellow_tripdata_2022-01.parquet ya existe. Se omite descarga.
2025-04-26 12:41:59,274 - INFO - yellow_tripdata_2022-02.parquet ya existe. Se omite descarga.
2025-04-26 12:41:59,274 - INFO - yellow_tripdata_2022-03.parquet ya existe. Se omite descarga.
2025-04-26 12:41:59,274 - INFO - yellow_tripdata_2022-04.parquet ya existe. Se omite descarga.
2025-04-26 12:41:59,274 - INFO - yellow_tripdata_2022-05.parquet ya existe. Se omite descarga.
2025-04-26 12:41:59,274 - INFO - yellow_tripdata_2022-06.parquet ya existe. Se omite descarga.
2025-04-26 12:41:59,274 - INFO - yellow_tripdata_2022-07.parquet ya existe. Se omite descarga.
2025-04-26 12:41:59,276 - INFO - yellow_tripdata_2022-08.parquet ya existe. Se omite descarga.
2025-04-26 12:41:59,276 - INFO - yellow_tripdata_2022-09.parquet ya existe. Se omite descarga.
2025-04-26 12:41:59,276 - INFO - yellow_tripdata_2022-10.parquet ya existe. Se omite descarga.
2025-04-26 12:41:59,276 - INFO - yellow_tripdata_2022-11.parquet ya existe. Se omite descarga.
2025-04-26 12:41:59,276 - INFO - yellow_tripdata_2022-12.parquet ya existe. Se omite descarga.
2025-04-26 12:41:59,276 - INFO - \U0001f4c2 Cargando archivos Parquet en Spark...
2025-04-26 12:42:05,286 - INFO - \u2705 Datos cargados con 39656098 registros.
2025-04-26 12:42:05,747 - INFO - Registros cargados en Raw Layer: 39656098
2025-04-26 12:42:05,747 - INFO - \U0001f4be Guardando datos RAW...
2025-04-26 12:42:25,726 - INFO - Error while receiving.
Traceback (most recent call last):
  File "C:\Python311\Lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [WinError 10054] Se ha forzado la interrupciï¿½n de una conexiï¿½n existente por el host remoto
2025-04-26 12:42:25,812 - INFO - Closing down clientserver connection
2025-04-26 12:42:25,812 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "C:\Python311\Lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [WinError 10054] Se ha forzado la interrupciï¿½n de una conexiï¿½n existente por el host remoto

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Python311\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-04-26 12:42:25,837 - INFO - Closing down clientserver connection
2025-04-26 12:42:25,837 - ERROR - \u274c ERROR en la ejecuciï¿½n: An error occurred while calling o36.parquet
2025-04-26 12:42:25,852 - INFO - Closing down clientserver connection
2025-04-26 12:47:55,055 - INFO - Iniciando ejecuciï¿½n del pipeline...
2025-04-26 12:47:55,055 - INFO - Iniciando sesiï¿½n de Spark...
2025-04-26 12:47:56,437 - INFO - \U0001f4e5 Descargando archivos Parquet desde la web pï¿½blica...
2025-04-26 12:47:56,438 - INFO - yellow_tripdata_2022-01.parquet ya existe. Se omite descarga.
2025-04-26 12:47:56,439 - INFO - yellow_tripdata_2022-02.parquet ya existe. Se omite descarga.
2025-04-26 12:47:56,439 - INFO - yellow_tripdata_2022-03.parquet ya existe. Se omite descarga.
2025-04-26 12:47:56,440 - INFO - yellow_tripdata_2022-04.parquet ya existe. Se omite descarga.
2025-04-26 12:47:56,440 - INFO - yellow_tripdata_2022-05.parquet ya existe. Se omite descarga.
2025-04-26 12:47:56,440 - INFO - yellow_tripdata_2022-06.parquet ya existe. Se omite descarga.
2025-04-26 12:47:56,441 - INFO - yellow_tripdata_2022-07.parquet ya existe. Se omite descarga.
2025-04-26 12:47:56,441 - INFO - yellow_tripdata_2022-08.parquet ya existe. Se omite descarga.
2025-04-26 12:47:56,441 - INFO - yellow_tripdata_2022-09.parquet ya existe. Se omite descarga.
2025-04-26 12:47:56,443 - INFO - yellow_tripdata_2022-10.parquet ya existe. Se omite descarga.
2025-04-26 12:47:56,443 - INFO - yellow_tripdata_2022-11.parquet ya existe. Se omite descarga.
2025-04-26 12:47:56,443 - INFO - yellow_tripdata_2022-12.parquet ya existe. Se omite descarga.
2025-04-26 12:47:56,443 - INFO - \U0001f4c2 Cargando archivos Parquet en Spark...
2025-04-26 12:48:01,107 - INFO - \u2705 Datos cargados con 39656098 registros.
2025-04-26 12:48:01,585 - INFO - Registros cargados en Raw Layer: 39656098
2025-04-26 12:48:01,585 - INFO - \U0001f4be Guardando datos RAW...
2025-04-26 12:48:41,153 - INFO - \U0001f4be Datos guardados en: ./output/raw_data
2025-04-26 12:48:41,181 - INFO - \U0001f6e0 Procesando capa Trusted...
2025-04-26 12:48:48,221 - INFO - Registros despuï¿½s de limpieza en Trusted Layer: 38839931
2025-04-26 12:49:48,490 - INFO - \U0001f4ca Calculando KPIs en capa Refined...
2025-04-26 12:50:09,231 - INFO - \U0001f680 Proceso completado en 134.17 segundos.
2025-04-26 12:50:13,739 - INFO - Closing down clientserver connection
2025-04-26 12:53:31,022 - INFO - Iniciando ejecuciï¿½n del pipeline...
2025-04-26 12:53:31,022 - INFO - Iniciando sesiï¿½n de Spark...
2025-04-26 12:53:32,031 - INFO - \U0001f4e5 Descargando archivos Parquet desde la web pï¿½blica...
2025-04-26 12:53:32,032 - INFO - yellow_tripdata_2022-01.parquet ya existe. Se omite descarga.
2025-04-26 12:53:32,032 - INFO - yellow_tripdata_2022-02.parquet ya existe. Se omite descarga.
2025-04-26 12:53:32,032 - INFO - yellow_tripdata_2022-03.parquet ya existe. Se omite descarga.
2025-04-26 12:53:32,034 - INFO - yellow_tripdata_2022-04.parquet ya existe. Se omite descarga.
2025-04-26 12:53:32,034 - INFO - yellow_tripdata_2022-05.parquet ya existe. Se omite descarga.
2025-04-26 12:53:32,034 - INFO - yellow_tripdata_2022-06.parquet ya existe. Se omite descarga.
2025-04-26 12:53:32,034 - INFO - yellow_tripdata_2022-07.parquet ya existe. Se omite descarga.
2025-04-26 12:53:32,034 - INFO - yellow_tripdata_2022-08.parquet ya existe. Se omite descarga.
2025-04-26 12:53:32,034 - INFO - yellow_tripdata_2022-09.parquet ya existe. Se omite descarga.
2025-04-26 12:53:32,034 - INFO - yellow_tripdata_2022-10.parquet ya existe. Se omite descarga.
2025-04-26 12:53:32,034 - INFO - yellow_tripdata_2022-11.parquet ya existe. Se omite descarga.
2025-04-26 12:53:32,034 - INFO - yellow_tripdata_2022-12.parquet ya existe. Se omite descarga.
2025-04-26 12:53:32,034 - INFO - \U0001f4c2 Cargando archivos Parquet en Spark...
2025-04-26 12:53:37,837 - INFO - \u2705 Datos cargados con 39656098 registros.
2025-04-26 12:53:38,177 - INFO - Registros cargados en Raw Layer: 39656098
2025-04-26 12:53:38,177 - INFO - \U0001f4be Guardando datos RAW...
2025-04-26 12:54:17,902 - INFO - \U0001f4be Datos guardados en: ./output/raw_data
2025-04-26 12:54:17,918 - INFO - \U0001f6e0 Procesando capa Trusted...
2025-04-26 12:54:26,072 - INFO - Registros despuï¿½s de limpieza en Trusted Layer: 38839931
2025-04-26 12:55:18,625 - INFO - \U0001f4ca Calculando KPIs en capa Refined...
2025-04-26 12:55:35,689 - INFO - \U0001f680 Proceso completado en 124.66 segundos.
2025-04-26 12:55:38,318 - INFO - Closing down clientserver connection
2025-04-26 15:41:19,892 - INFO - Iniciando ejecución del pipeline...
2025-04-26 15:41:19,893 - INFO - Iniciando sesión de Spark...
2025-04-26 15:41:19,897 - INFO - \U0001f4e5 Descargando archivos Parquet desde la web pública...
2025-04-26 15:41:19,899 - INFO - yellow_tripdata_2022-01.parquet ya existe. Se omite descarga.
2025-04-26 15:41:19,901 - INFO - yellow_tripdata_2022-02.parquet ya existe. Se omite descarga.
2025-04-26 15:41:19,902 - INFO - yellow_tripdata_2022-03.parquet ya existe. Se omite descarga.
2025-04-26 15:41:19,902 - INFO - yellow_tripdata_2022-04.parquet ya existe. Se omite descarga.
2025-04-26 15:41:19,903 - INFO - yellow_tripdata_2022-05.parquet ya existe. Se omite descarga.
2025-04-26 15:41:19,903 - INFO - yellow_tripdata_2022-06.parquet ya existe. Se omite descarga.
2025-04-26 15:41:19,904 - INFO - yellow_tripdata_2022-07.parquet ya existe. Se omite descarga.
2025-04-26 15:41:19,905 - INFO - yellow_tripdata_2022-08.parquet ya existe. Se omite descarga.
2025-04-26 15:41:19,905 - INFO - yellow_tripdata_2022-09.parquet ya existe. Se omite descarga.
2025-04-26 15:41:19,905 - INFO - yellow_tripdata_2022-10.parquet ya existe. Se omite descarga.
2025-04-26 15:41:19,906 - INFO - yellow_tripdata_2022-11.parquet ya existe. Se omite descarga.
2025-04-26 15:41:19,906 - INFO - yellow_tripdata_2022-12.parquet ya existe. Se omite descarga.
2025-04-26 15:41:19,906 - INFO - \U0001f4c2 Cargando archivos Parquet en Spark...
2025-04-26 15:41:21,171 - INFO - \u2705 Datos cargados con 39656598 registros.
2025-04-26 15:41:21,751 - INFO - Registros cargados en Raw Layer: 39656598
2025-04-26 15:41:21,751 - INFO - \U0001f4be Guardando datos RAW...
2025-04-26 15:42:06,501 - INFO - \U0001f4be Datos guardados en: ./output/raw_data
2025-04-26 15:42:06,510 - INFO - \U0001f6e0 Procesando capa Trusted...
2025-04-26 15:42:12,438 - INFO - Registros después de limpieza en Trusted Layer: 38840423
2025-04-26 15:43:02,043 - INFO - \U0001f4ca Calculando KPIs en capa Refined...
2025-04-26 15:43:15,359 - INFO - \U0001f680 Proceso completado en 115.46 segundos.
2025-04-26 15:43:19,291 - INFO - Closing down clientserver connection
